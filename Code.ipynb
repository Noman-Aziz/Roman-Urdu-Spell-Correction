{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "i18-1561",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EOd_QY4-VTS"
      },
      "source": [
        "**Noman Aziz**\n",
        "---\n",
        "**i181561@nu.edu.pk**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jehJCaIo-ye1"
      },
      "source": [
        "#Documentation\n",
        "\n",
        "1.   Data Loading\n",
        "  *   I load data.txt and misspellings.txt into python lists using google drive.\n",
        "2.   Uni-Gram Model Training\n",
        "  *   Then i generate my language model i.e, i generate unigrams using data list and calculate their probabilities and store them in python dictionary data structure.\n",
        "3.   Error Tables Generation\n",
        "  *   Then i generate empty python dictionary which contain tuples as key.\n",
        "  *   I start from ('#','#'), ('#','a') to ('z','y'), ('z','z') and assign these keys 0 value\n",
        "  *   Then i populate these dictionaries using misspellings.txt file. I determine the type of edit between wrong and correct word, and update the specific edit table value accordingly.\n",
        "4.    P(x|w) calculation\n",
        "  *    First i generate a Chars list which contain count of individual english letters in the alphabet along with '#'. It is stored in python dictionary\n",
        "  *    Then i generate a CharsDouble list which contain count of bigram (two) english letters in the alphabet along with '#'. It is stored in python dictionary as a tuple.\n",
        "  *    Then i use the formula provided in noisy-channel.pdf file to calculate P(x|w). I pass incorrect letter, correct letter and type of edit to the function.\n",
        "5.    Calculation of List of Candidate Words\n",
        "  *    I generate list of candidate words from the typed word using edit distance formula\n",
        "  *    I used Damerauâ€“Levenshtein distance for the edit distance\n",
        "  *    I improved the performance of this function by maintaining a memory which keeps count of the words whose edit distance was already calculated so it avoids repeating recursive iterations\n",
        "  *    My fain candidate generation function use this edit distance function and add only those words in the list who has edit distance of 1 or 0\n",
        "6.    Main Function\n",
        "  *    It first sends a typed word to candidate word function which generate a list of candidate words\n",
        "  *    if there are no candidate words, then the typed word will remain as it is (no auto correction)\n",
        "  *    If there are candidate words, it sends the list and the typed word to the suggested word function.\n",
        "  *    the suggested word function iterates over the candidate word list, calculate the editType and letter1 and letter2 of that particular edit. Then it calculates P(x|w) using previous defined function and multiply it with P(w) which we get from the unigrams dictionary.\n",
        "  *    This function returns the candidate word with highest probability and if a case occurs, in which the edit distance was 0, then it assumes that the typed word is the correct word and returns it back since it has the highest probability."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtIFd6KqzfsH"
      },
      "source": [
        "#Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1gYGhyvzbRq"
      },
      "source": [
        "from google.colab import files, drive\n",
        "import csv\n",
        "import itertools"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rH-0zMGzzjbA"
      },
      "source": [
        "#Importing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCyshHoJzki8",
        "outputId": "14a6fff6-1e1d-4c7f-a6e6-7a2d1f11647a"
      },
      "source": [
        "#Loading File from Uploading\n",
        "#uploadedFiles = files.upload()\n",
        "\n",
        "#Loading Files from Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#Loading Data.txt file\n",
        "with open('/content/drive/My Drive/data.txt', 'rt', encoding=\"utf-8\") as f:\n",
        "  reader = csv.reader(f)\n",
        "  data = list(reader)\n",
        "f.close()\n",
        "\n",
        "#Loading Misspellings.txt file\n",
        "with open('/content/drive/My Drive/misspellings.txt', 'rt', encoding=\"utf-8\") as f:\n",
        "  reader = csv.reader(f)\n",
        "  misSpellings = list(reader)\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NW33QVFV2qiL"
      },
      "source": [
        "#Language Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUk5YQ510i98"
      },
      "source": [
        "unigrams = dict()\n",
        "\n",
        "def genUnigrams():\n",
        "  lenCorpus = 0\n",
        "  for line in data:\n",
        "    splittedWords = line[0].split(' ')\n",
        "    for word in splittedWords:\n",
        "      lenCorpus += 1\n",
        "      if word not in unigrams:\n",
        "        unigrams[word] = 1\n",
        "      else:\n",
        "        unigrams[word] += 1\n",
        "\n",
        "  #Assigning Probabilities to Unigrams\n",
        "  for key in unigrams:\n",
        "    unigrams[key] = (unigrams[key] / lenCorpus)\n",
        "\n",
        "genUnigrams()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaMOPkS7BIKK"
      },
      "source": [
        "#Error Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZIdIWgwG-Pk"
      },
      "source": [
        "##Generating Initial Insert, Delete, Subsitute and Transpose Tables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PRzrczO-X1m"
      },
      "source": [
        "#Generating Initial Insert, Delete, Subsitute and Transpose Tables\n",
        "def genTable():\n",
        "  dictionary = dict()\n",
        "  alphabets = ['#', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
        "  for letter1 in alphabets:\n",
        "    for letter2 in alphabets:\n",
        "      combination = (letter1, letter2)\n",
        "      dictionary[combination] = 0\n",
        "  return dictionary\n",
        "\n",
        "insertTable = genTable()\n",
        "deleteTable = genTable()\n",
        "subsitutionTable = genTable()\n",
        "transposeTable = genTable()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cL75Y-f_LMvc"
      },
      "source": [
        "##Auxilary Handler Functions for Tables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jH8lHGqcLQ51"
      },
      "source": [
        "def handleInsertTable(correctWord, wrongWord):\n",
        "  for index, (letter1, letter2) in enumerate(itertools.zip_longest(correctWord, wrongWord)):\n",
        "    #Insertion at Beginning\n",
        "    if (index == 0) and (letter1 != letter2):\n",
        "      insertTable[('#', letter2)] += 1\n",
        "      return \"Insertion\", \"#\", letter2\n",
        "\n",
        "    #Insertion at End or Middle\n",
        "    elif (letter1 == None) or ((letter1 != letter2) and (index != 0)):\n",
        "      insertTable[(correctWord[index-1], letter2)] += 1\n",
        "      return \"Insertion\", correctWord[index-1], letter2\n",
        "\n",
        "def handleDeleteTable(correctWord, wrongWord):\n",
        "  for index, (letter1, letter2) in enumerate(itertools.zip_longest(correctWord, wrongWord)):\n",
        "    #delete at start\n",
        "    if (index==0) and (letter1 != letter2):\n",
        "      deleteTable[('#', letter1)] += 1\n",
        "      return \"Deletion\", \"#\", letter1\n",
        "\n",
        "    #delete at beginning or end\n",
        "    elif (index!=0) and (letter1 != letter2):\n",
        "      deleteTable[(correctWord[index-1], letter1)] += 1\n",
        "      return \"Deletion\", correctWord[index-1], letter1\n",
        "\n",
        "def handleSubsitutionAndTransposeTable(correctWord, wrongWord):\n",
        "  for index, (letter1, letter2) in enumerate(zip(correctWord, wrongWord)):\n",
        "    if letter1 != letter2:\n",
        "      #Transpose Case\n",
        "      if (index + 1 < len(wrongWord)) and (correctWord[index] == wrongWord[index + 1]):\n",
        "        transposeTable[(letter1, letter2)] += 1\n",
        "        return \"Transpose\", letter1, letter2\n",
        "      #Subsitution Case\n",
        "      else:\n",
        "        subsitutionTable[(letter1, letter2)] += 1\n",
        "        return \"Subsitution\", letter1, letter2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGCMotcvrFpa"
      },
      "source": [
        "##Determines Type of Edit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCaCYJGVqVum"
      },
      "source": [
        "def determineTypeOfEdit(wrongWord, correctWord):\n",
        "    if(len(wrongWord) > len(correctWord)):\n",
        "      return handleInsertTable(correctWord, wrongWord)\n",
        "    elif(len(wrongWord) < len(correctWord)):\n",
        "      return handleDeleteTable(correctWord, wrongWord)\n",
        "    else:\n",
        "      return handleSubsitutionAndTransposeTable(correctWord, wrongWord)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QSRGhL0I5rC"
      },
      "source": [
        "##Populating Tables Values from Misspellings File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75gMLfqgI9I0"
      },
      "source": [
        "def populateTables():\n",
        "  initialLine = True\n",
        "  for line in misSpellings:\n",
        "    #Ignoring the First Line\n",
        "    if(initialLine):\n",
        "      initialLine = False\n",
        "      continue\n",
        "\n",
        "    correctWord = line[0].strip().lower()\n",
        "    wrongWords = line[1].split('\\t')\n",
        "    for word in wrongWords:\n",
        "      wrongWord = word.strip().lower()\n",
        "\n",
        "      #Determining Type of Edit and Updating Table Accordingly\n",
        "      determineTypeOfEdit(wrongWord, correctWord)\n",
        "\n",
        "populateTables()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCMYlRIEcX9h"
      },
      "source": [
        "#P(x|w) Calculation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rig-aBV0gZh1"
      },
      "source": [
        "##Chars (Single Letter)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtbqE4g5cclK"
      },
      "source": [
        "charsSingle = dict()\n",
        "\n",
        "def genCharsSingle():\n",
        "  charsSingle['#'] = 0\n",
        "  for line in data:\n",
        "    splittedWords = line[0].split(' ')\n",
        "    for word in splittedWords:\n",
        "      charsSingle['#'] += 1\n",
        "      for letter in word.strip().lower():\n",
        "        if letter not in charsSingle:\n",
        "          charsSingle[letter] = 1\n",
        "        else:\n",
        "          charsSingle[letter] += 1\n",
        "\n",
        "genCharsSingle()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaQ8pHsBiSbp"
      },
      "source": [
        "##Chars (Double Letter)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YK5nEsFhqHJ"
      },
      "source": [
        "charsDouble = dict()\n",
        "\n",
        "def genCharsDouble():\n",
        "  for line in data:\n",
        "    splittedWords = line[0].split(' ')\n",
        "    for word in splittedWords:\n",
        "      filteredWord = word.strip().lower()\n",
        "\n",
        "      if ('#', word[0]) in charsDouble:\n",
        "        charsDouble[('#', filteredWord[0])] += 1\n",
        "      else:\n",
        "        charsDouble[('#', filteredWord[0])] = 1\n",
        "\n",
        "      for index in range(len(filteredWord)-1):\n",
        "        if (filteredWord[index], filteredWord[index+1]) not in charsDouble:\n",
        "          charsDouble[(filteredWord[index], filteredWord[index+1])] = 1\n",
        "        else:\n",
        "          charsDouble[(filteredWord[index], filteredWord[index+1])] += 1\n",
        "\n",
        "genCharsDouble()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrvrPXPOk6RZ"
      },
      "source": [
        "##Function to calculate P(x|w)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VGKAJUIjhoI"
      },
      "source": [
        "def calcPxw(t, c, method):\n",
        "  if method == \"Insertion\":\n",
        "    return (insertTable[(c, t)] / charsSingle[c])\n",
        "  elif method == \"Deletion\":\n",
        "    return (deleteTable[(c, t)] / charsDouble[(c, t)])\n",
        "  elif method == \"Subsitution\":\n",
        "    return (subsitutionTable[(c, t)] / charsSingle[c])\n",
        "  elif method == \"Transpose\":\n",
        "    return (transposeTable[(c, t)] / charsDouble[(c, t)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIs3bI8VIN7e"
      },
      "source": [
        "#Candidate Words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8Q3V5cmIWdv"
      },
      "source": [
        "##Edit Distance Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPjh3OAPIShH"
      },
      "source": [
        "#Implemented using Damerauâ€“Levenshtein distance\n",
        "#We Add memory to it in order to increase efficiency (performance) of our function\n",
        "memory = {}\n",
        "def getEditDistance(word1, word2):\n",
        "\n",
        "  i = len(word1)\n",
        "  j = len(word2)\n",
        "\n",
        "  distances = []\n",
        "\n",
        "  if (i == 0):\n",
        "    return j\n",
        "  if (j == 0):\n",
        "    return i\n",
        "\n",
        "  if (i > 0):\n",
        "    #Deletion\n",
        "    parameter = (word1[:-1], word2)\n",
        "\n",
        "    if parameter not in memory:\n",
        "      memory[parameter] = getEditDistance(word1[:-1], word2)\n",
        "\n",
        "    distances.append(memory[parameter] + 1)\n",
        "\n",
        "  if (j > 0):\n",
        "    #Insertion\n",
        "    parameter = (word1, word2[:-1])\n",
        "\n",
        "    if parameter not in memory:\n",
        "      memory[parameter] = getEditDistance(word1, word2[:-1])\n",
        "\n",
        "    distances.append(memory[parameter] + 1)\n",
        "\n",
        "  if (i > 0) and (j > 0):\n",
        "    #Subsitution\n",
        "    parameter = (word1[:-1], word2[:-1])\n",
        "\n",
        "    if(word1[-1] == word2[-1]):\n",
        "      cost = 0\n",
        "    else:\n",
        "      cost = 1\n",
        "\n",
        "    if parameter not in memory:\n",
        "      memory[parameter] = getEditDistance(word1[:-1], word2[:-1])\n",
        "  \n",
        "    distances.append(memory[parameter] + cost)\n",
        "\n",
        "  if (i > 1) and (j > 1) and (word1[-1] == word2[-2]) and (word1[-2] == word2[-1]):\n",
        "    #Tranposition\n",
        "    parameter = (word1[:-2], word2[:-2])\n",
        "\n",
        "    if parameter not in memory:\n",
        "      memory[parameter] = getEditDistance(word1[:-2], word2[:-2])\n",
        "\n",
        "    distances.append(memory[parameter] + 1)\n",
        "\n",
        "  return min(distances)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Swg9bV_IiVyf"
      },
      "source": [
        "##Generating Candidate Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujLyn8dxhePH"
      },
      "source": [
        "def getCandidateWords(word):\n",
        "  candidateWords = []\n",
        "\n",
        "  for key in unigrams:\n",
        "    distance = getEditDistance(word.lower(), key.lower())\n",
        "    if (distance == 1) or (distance == 0):\n",
        "      candidateWords.append((key, distance))\n",
        "\n",
        "  return candidateWords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kod9soQpph5Q"
      },
      "source": [
        "#Suggested Word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4T1N2F-jpmpE"
      },
      "source": [
        "def getSuggestedWord(candidateWords, typedWord):\n",
        "  w = dict()\n",
        "  suggestedWord = \"\"  \n",
        "  suggestedWordProb = 0\n",
        "\n",
        "  for word in candidateWords:\n",
        "    #Same Word with Edit Distance 0, No Need to Autocorrect\n",
        "    if (word[1] == 0):\n",
        "      return word[0], {}\n",
        "\n",
        "    editType, letter1, letter2 = determineTypeOfEdit(typedWord, word[0])\n",
        "    Pxw = calcPxw(letter2, letter1, editType)\n",
        "    Pw = unigrams[word[0]]\n",
        "    print(f\"Candidate Word : {word[0]}\")\n",
        "    print(f\"\\tEdit Type : {editType}\\n\\tLetter 1 : {letter1}\\n\\tLetter 2 : {letter2}\")\n",
        "    print(f\"\\tP(x|w) = {Pxw}\")\n",
        "    print(f\"\\tP(w) = {Pw}\")\n",
        "    print(f\"\\tP(x|w) * P(w) : {Pxw * Pw}\")\n",
        "    w[word[0]] = Pxw * Pw\n",
        "    if (Pxw * Pw) > suggestedWordProb:\n",
        "      suggestedWord = word[0]\n",
        "      suggestedWordProb = Pxw * Pw\n",
        "\n",
        "  return suggestedWord, w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FxnXIKRywL9"
      },
      "source": [
        "#Main Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "937IEGXktcO8"
      },
      "source": [
        "typedWord = \"iksa\"\n",
        "candidateWords = getCandidateWords(typedWord)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjoi_hbftt1f",
        "outputId": "ea5bfb47-37a8-4354-b904-084bfd2eca7b"
      },
      "source": [
        "if len(candidateWords) == 0:\n",
        "  suggestedWord = typedWord\n",
        "  allWordsProb = dict()\n",
        "else: \n",
        "  suggestedWord, allWordsProb = getSuggestedWord(candidateWords, typedWord)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Candidate Word : kisa\n",
            "\tEdit Type : Transpose\n",
            "\tLetter 1 : k\n",
            "\tLetter 2 : i\n",
            "\tP(x|w) = 6.39544985061295e-06\n",
            "\tP(w) = 1.7407576372259819e-07\n",
            "\tP(x|w) * P(w) : 1.1132928170950259e-12\n",
            "Candidate Word : iska\n",
            "\tEdit Type : Transpose\n",
            "\tLetter 1 : s\n",
            "\tLetter 2 : k\n",
            "\tP(x|w) = 0.00015742907820027078\n",
            "\tP(w) = 1.7439226511118473e-05\n",
            "\tP(x|w) * P(w) : 2.7454413541711054e-09\n",
            "Candidate Word : isa\n",
            "\tEdit Type : Insertion\n",
            "\tLetter 1 : i\n",
            "\tLetter 2 : k\n",
            "\tP(x|w) = 1.2430972064675275e-05\n",
            "\tP(w) = 2.1474619215596883e-05\n",
            "\tP(x|w) * P(w) : 2.669503915686237e-10\n",
            "Candidate Word : ikas\n",
            "\tEdit Type : Transpose\n",
            "\tLetter 1 : a\n",
            "\tLetter 2 : s\n",
            "\tP(x|w) = 5.477846025573716e-05\n",
            "\tP(w) = 3.7980166630385056e-06\n",
            "\tP(x|w) * P(w) : 2.0804950482688225e-10\n",
            "Candidate Word : ika\n",
            "\tEdit Type : Insertion\n",
            "\tLetter 1 : k\n",
            "\tLetter 2 : s\n",
            "\tP(x|w) = 7.353873076258272e-06\n",
            "\tP(w) = 4.589270134504861e-07\n",
            "\tP(x|w) * P(w) : 3.374891008181148e-12\n",
            "Candidate Word : ikla\n",
            "\tEdit Type : Subsitution\n",
            "\tLetter 1 : l\n",
            "\tLetter 2 : s\n",
            "\tP(x|w) = 1.8985813444210484e-05\n",
            "\tP(w) = 6.804779854610656e-07\n",
            "\tP(x|w) * P(w) : 1.2919428084855966e-11\n",
            "Candidate Word : ikha\n",
            "\tEdit Type : Subsitution\n",
            "\tLetter 1 : h\n",
            "\tLetter 2 : s\n",
            "\tP(x|w) = 1.0000017948750165e-05\n",
            "\tP(w) = 1.930658470377907e-06\n",
            "\tP(x|w) * P(w) : 1.9306619356685607e-11\n",
            "Candidate Word : issa\n",
            "\tEdit Type : Transpose\n",
            "\tLetter 1 : s\n",
            "\tLetter 2 : k\n",
            "\tP(x|w) = 0.00016792435008028883\n",
            "\tP(w) = 7.43778263178374e-07\n",
            "\tP(x|w) * P(w) : 1.2489848144807448e-10\n",
            "Candidate Word : insa\n",
            "\tEdit Type : Subsitution\n",
            "\tLetter 1 : n\n",
            "\tLetter 2 : k\n",
            "\tP(x|w) = 1.3960285325491317e-05\n",
            "\tP(w) = 2.057259025812524e-07\n",
            "\tP(x|w) * P(w) : 2.8719922988785142e-12\n",
            "Candidate Word : ksa\n",
            "\tEdit Type : Insertion\n",
            "\tLetter 1 : #\n",
            "\tLetter 2 : i\n",
            "\tP(x|w) = 1.1204149155963591e-05\n",
            "\tP(w) = 1.7407576372259819e-07\n",
            "\tP(x|w) * P(w) : 1.950370821186266e-12\n",
            "Candidate Word : ikka\n",
            "\tEdit Type : Subsitution\n",
            "\tLetter 1 : k\n",
            "\tLetter 2 : s\n",
            "\tP(x|w) = 5.8963486827656415e-06\n",
            "\tP(w) = 2.6902618029856084e-06\n",
            "\tP(x|w) * P(w) : 1.586272163832891e-11\n",
            "Candidate Word : iksha\n",
            "\tEdit Type : Deletion\n",
            "\tLetter 1 : s\n",
            "\tLetter 2 : h\n",
            "\tP(x|w) = 1.144016194693252e-05\n",
            "\tP(w) = 1.1077548600528975e-07\n",
            "\tP(x|w) * P(w) : 1.2672894996506718e-12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbqVwxn429Z6",
        "outputId": "513f6b2a-c549-476e-d21e-5f7c4a04c1d1"
      },
      "source": [
        "print(f\"Typed Word : {typedWord}\")\n",
        "print(f\"Auto-Corrected Word : {suggestedWord}\")\n",
        "print(f\"All checked words with probabilities : {allWordsProb}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Typed Word : iksa\n",
            "Auto-Corrected Word : iska\n",
            "All checked words with probabilities : {'kisa': 1.1132928170950259e-12, 'iska': 2.7454413541711054e-09, 'isa': 2.669503915686237e-10, 'ikas': 2.0804950482688225e-10, 'ika': 3.374891008181148e-12, 'ikla': 1.2919428084855966e-11, 'ikha': 1.9306619356685607e-11, 'issa': 1.2489848144807448e-10, 'insa': 2.8719922988785142e-12, 'ksa': 1.950370821186266e-12, 'ikka': 1.586272163832891e-11, 'iksha': 1.2672894996506718e-12}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdFtbL9l3YLs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}